name_model = "10B"
project = "10B_zero_band"
wandb_resume = false

[train]
micro_bs = 1
ac_ckpt = true

[optim]
sched_type = "wsd-sqrt"
batch_size = 128 #1M tokens bs
warmup_steps = 1000
total_steps = 1_000_000_000_000


z_loss = true

[optim.optim]
lr = 7.5e-5
betas1 = 0.9
betas2 = 0.95
weight_decay = 0.1

[data]
seq_length = 8192
dataset_name_or_paths = "/data/datasets/fineweb-edu,/data/datasets/fineweb,/data/datasets/StackV1-popular,/data/datasets/dclm-baseline-1.0-parquet,/data/datasets/open-web-math"
dataset_ratio = "55:10:20:10:5"
num_workers = 4
reverse_data_files = true
split_by_data_rank = false # the 10b training assume that data was already split by datarank. Keeping this for backward compatibility


[diloco]
inner_steps = 100
compression = "uint8"

[ckpt]
interval = 100
topk = 40
path = "/data/10B"
remote_data_path = "/data/10B_data_ckpt"
