name_model = "7B"
project = "debug_7B_zero_band"
type_model = "llama2"

[train]
micro_bs = 1

[optim]
batch_size = 1024 #2M tokens bs
warmup_steps = 1000
total_steps = 88_000

[optim.optim]
lr = 3e-4

[data]
seq_length = 2048