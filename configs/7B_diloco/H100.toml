name_model = "7B"
project = "debug_7B_zero_band"
type_model = "llama2"

[train]
micro_bs = 1

[optim]
batch_size = 1024 #2M tokens bs
warmup_steps = 1000
total_steps = 88_000

[optim.optim]
lr = 3e-4

[data]
seq_length = 2048

[diloco]
inner_steps = 50

[ckpt]
path = "/data/outputs_1b_diloco_50"
interval = 1000

