# Example RL training configuration
# Usage: prime rl -c examples/rl_config.toml

model = "PrimeIntellect/Qwen3-0.6B-Reverse-Text-SFT"
environments = ["reverse-text"]

rollouts = 8      # number of attempts per prompt/example
max_steps = 100   # total training iterations
seq_len = 4096    # max tokens per response

# name = "my-experiment"

# [wandb]
# entity = "my-team"
# project = "my-project"
# name = "experiment-1"
